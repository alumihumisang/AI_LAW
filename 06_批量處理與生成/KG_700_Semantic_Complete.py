#!/usr/bin/env python3
"""
KG_700_Semantic_Complete.py
å®Œæ•´çš„èªç¾©åŒ–æ³•å¾‹æ–‡ä»¶è™•ç†ç³»çµ± - å«äº’å‹•ç•Œé¢
åŸºæ–¼èªç¾©ç†è§£çš„é€šç”¨æ³•å¾‹æ–‡ä»¶è™•ç†ï¼Œå…·å‚™çœŸæ­£çš„æ³›åŒ–èƒ½åŠ›
"""

import os
import re
import json
import requests
import time
import sys
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
from collections import Counter

# å°å…¥å¿…è¦æ¨¡çµ„
try:
    import torch
    from transformers import AutoTokenizer, AutoModel
    from elasticsearch import Elasticsearch
    from neo4j import GraphDatabase
    from dotenv import load_dotenv
    FULL_MODE = True
    print("âœ… å®Œæ•´æ¨¡å¼ï¼šæ‰€æœ‰æª¢ç´¢åŠŸèƒ½å¯ç”¨")
except ImportError as e:
    print(f"âš ï¸ éƒ¨åˆ†æ¨¡çµ„æœªå®‰è£ï¼š{e}")
    print("âš ï¸ ä½¿ç”¨ç°¡åŒ–æ¨¡å¼ï¼ˆåƒ…LLMç”ŸæˆåŠŸèƒ½ï¼‰")
    FULL_MODE = False

# å°å…¥èªç¾©è™•ç†å™¨
try:
    from KG_700_Semantic_Universal import SemanticLegalProcessor
    SEMANTIC_PROCESSOR_AVAILABLE = True
    print("âœ… èªç¾©è™•ç†å™¨è¼‰å…¥æˆåŠŸ")
except ImportError:
    SEMANTIC_PROCESSOR_AVAILABLE = False
    print("âš ï¸ èªç¾©è™•ç†å™¨æœªæ‰¾åˆ°")

# ===== åŸºæœ¬è¨­å®š =====
LLM_URL = "http://localhost:11434/api/generate"
DEFAULT_MODEL = "gemma3:27b"

# ===== æª¢ç´¢ç³»çµ±è¨­å®š =====
if FULL_MODE:
    # è¼‰å…¥ç’°å¢ƒè®Šæ•¸
    env_path = os.path.join(os.path.dirname(__file__), '..', '01_è¨­å®šèˆ‡é…ç½®', '.env')
    load_dotenv(dotenv_path=env_path)
    
    # åµŒå…¥æ¨¡å‹è¨­å®š
    BERT_MODEL = "shibing624/text2vec-base-chinese"
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    try:
        TOKENIZER = AutoTokenizer.from_pretrained(BERT_MODEL)
        MODEL = AutoModel.from_pretrained(BERT_MODEL, torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32).to(device)
        print("âœ… åµŒå…¥æ¨¡å‹è¼‰å…¥æˆåŠŸ")
    except Exception as e:
        print(f"âŒ åµŒå…¥æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
        FULL_MODE = False
    
    # ES å’Œ Neo4j é€£æ¥
    try:
        ES_HOST = os.getenv("ELASTIC_HOST")
        ES_USER = os.getenv("ELASTIC_USER")
        ES_PASSWORD = os.getenv("ELASTIC_PASSWORD")
        ES_AUTH = (ES_USER, ES_PASSWORD)
        
        # æ¸¬è©¦ ES é€£æ¥
        response = requests.get(f"{ES_HOST}/_cluster/health", auth=ES_AUTH, verify=False)
        if response.status_code != 200:
            raise Exception(f"ESé€£æ¥å¤±æ•—: {response.status_code}")
        
        NEO4J_DRIVER = GraphDatabase.driver(
            os.getenv("NEO4J_URI"),
            auth=(os.getenv("NEO4J_USERNAME"), os.getenv("NEO4J_PASSWORD")),
        )
        CHUNK_INDEX = "legal_kg_chunks"
        print("âœ… è³‡æ–™åº«é€£æ¥æˆåŠŸ")
    except Exception as e:
        print(f"âŒ è³‡æ–™åº«é€£æ¥å¤±æ•—: {e}")
        FULL_MODE = False

class SemanticLawsuitGenerator:
    """åŸºæ–¼èªç¾©ç†è§£çš„èµ·è¨´ç‹€ç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.semantic_processor = SemanticLegalProcessor() if SEMANTIC_PROCESSOR_AVAILABLE else None
        self.llm_url = LLM_URL
        self.model_name = DEFAULT_MODEL
        
    def call_llm(self, prompt: str, timeout: int = 180) -> str:
        """èª¿ç”¨LLM"""
        try:
            response = requests.post(
                self.llm_url,
                json={
                    "model": self.model_name,
                    "prompt": prompt,
                    "stream": False
                },
                timeout=timeout
            )
            
            if response.status_code == 200:
                result = response.json()
                return result.get("response", "").strip()
            else:
                return f"LLMèª¿ç”¨å¤±æ•—: {response.status_code}"
                
        except Exception as e:
            return f"LLMèª¿ç”¨éŒ¯èª¤: {e}"
    
    def extract_sections_semantic(self, text: str) -> Dict[str, str]:
        """åŸºæ–¼èªç¾©çš„æ®µè½æå–"""
        print("ğŸ“ ä½¿ç”¨èªç¾©ç†è§£æå–æ®µè½...")
        
        prompt = f"""ä½ æ˜¯æ³•å¾‹æ–‡ä»¶åˆ†æå°ˆå®¶ï¼Œè«‹å°‡ä»¥ä¸‹è»Šç¦æ¡ˆä»¶æè¿°åˆ†ç‚ºä¸‰å€‹æ¨™æº–æ®µè½ã€‚

ã€è¼¸å…¥æ–‡æœ¬ã€‘
{text}

ã€åˆ†æ®µè¦æ±‚ã€‘
è«‹å°‡å…§å®¹åˆ†ç‚ºä»¥ä¸‹ä¸‰å€‹éƒ¨åˆ†ï¼š
1. accident_facts - äº‹æ•…ç™¼ç”Ÿç·£ç”±å’Œç¶“é
2. injury_description - åŸå‘Šå—å‚·æƒ…å½¢å’Œå°±é†«éç¨‹  
3. damage_claims - è«‹æ±‚è³ å„Ÿçš„äº‹å¯¦æ ¹æ“šå’Œæå®³é …ç›®

ã€è¼¸å‡ºæ ¼å¼ã€‘
è«‹è¼¸å‡ºJSONæ ¼å¼ï¼š
{{
    "accident_facts": "äº‹æ•…ç¶“éå…§å®¹...",
    "injury_description": "å—å‚·æƒ…å½¢å…§å®¹...", 
    "damage_claims": "æå®³è³ å„Ÿå…§å®¹..."
}}

è«‹åˆ†æä¸¦è¼¸å‡ºJSONï¼š"""

        try:
            response = self.call_llm(prompt, timeout=120)
            
            # è§£æJSONå›æ‡‰
            try:
                sections = json.loads(response)
            except:
                json_match = re.search(r'\{.*\}', response, re.DOTALL)
                if json_match:
                    sections = json.loads(json_match.group(0))
                else:
                    print("âŒ æ®µè½JSONè§£æå¤±æ•—ï¼Œä½¿ç”¨åŸºæœ¬åˆ†æ®µ")
                    return self._fallback_section_extraction(text)
            
            print("âœ… èªç¾©æ®µè½æå–å®Œæˆ")
            return sections
            
        except Exception as e:
            print(f"âŒ èªç¾©æ®µè½æå–å¤±æ•—: {e}")
            return self._fallback_section_extraction(text)
    
    def _fallback_section_extraction(self, text: str) -> Dict[str, str]:
        """å‚™ç”¨æ®µè½æå–"""
        # ç°¡å–®çš„é—œéµè©åˆ†æ®µ
        sections = {
            "accident_facts": "",
            "injury_description": "",
            "damage_claims": ""
        }
        
        paragraphs = text.split('\n')
        current_section = "accident_facts"
        
        for para in paragraphs:
            if any(keyword in para for keyword in ['å—å‚·', 'è¨ºæ–·', 'é†«é™¢', 'æ²»ç™‚']):
                current_section = "injury_description"
            elif any(keyword in para for keyword in ['è²»ç”¨', 'æå¤±', 'è³ å„Ÿ', 'è«‹æ±‚']):
                current_section = "damage_claims"
            
            if para.strip():
                sections[current_section] += para + "\n"
        
        return sections
    
    def determine_case_type_semantic(self, text: str) -> str:
        """åŸºæ–¼èªç¾©çš„æ¡ˆä»¶åˆ†é¡"""
        print("ğŸ” ä½¿ç”¨èªç¾©ç†è§£é€²è¡Œæ¡ˆä»¶åˆ†é¡...")
        
        prompt = f"""ä½ æ˜¯äº¤é€šäº‹æ•…æ³•å¾‹å°ˆå®¶ï¼Œè«‹åˆ†æä»¥ä¸‹æ¡ˆä»¶ä¸¦åˆ¤æ–·æ¡ˆä»¶é¡å‹ã€‚

ã€æ¡ˆä»¶æè¿°ã€‘
{text}

ã€æ¡ˆä»¶é¡å‹ã€‘
è«‹å¾ä»¥ä¸‹é¡å‹ä¸­é¸æ“‡æœ€é©åˆçš„ï¼š
- ä¸€èˆ¬è»Šç¦ - æ™®é€šçš„è»Šè¼›ç¢°æ’äº‹æ•…
- æ©Ÿè»Šäº‹æ•… - æ¶‰åŠæ©Ÿè»Šçš„äº‹æ•…
- è¡Œäººäº‹æ•… - è»Šè¼›æ’æ“Šè¡Œäºº
- åœè»Šç³¾ç´› - åœè»Šç›¸é—œçš„æå®³
- å…¶ä»–äº¤é€šäº‹æ•… - ä¸å±¬æ–¼ä¸Šè¿°é¡å‹çš„äº¤é€šäº‹æ•…

ã€è¼¸å‡ºè¦æ±‚ã€‘
åªéœ€è¦å›ç­”æ¡ˆä»¶é¡å‹ï¼Œä¾‹å¦‚ï¼šä¸€èˆ¬è»Šç¦

è«‹åˆ†æä¸¦å›ç­”ï¼š"""

        try:
            response = self.call_llm(prompt, timeout=60)
            case_type = response.strip()
            print(f"âœ… æ¡ˆä»¶åˆ†é¡: {case_type}")
            return case_type
        except Exception as e:
            print(f"âŒ èªç¾©åˆ†é¡å¤±æ•—: {e}")
            return "ä¸€èˆ¬è»Šç¦"
    
    def generate_semantic_lawsuit(self, user_input: str) -> Dict[str, Any]:
        """å®Œæ•´çš„èªç¾©åŒ–èµ·è¨´ç‹€ç”Ÿæˆ"""
        print("ğŸš€ é–‹å§‹èªç¾©åŒ–èµ·è¨´ç‹€ç”Ÿæˆ...")
        print("=" * 80)
        
        results = {}
        
        try:
            # 1. æ®µè½æå–
            sections = self.extract_sections_semantic(user_input)
            results["sections"] = sections
            
            # 2. ç•¶äº‹äººæå–ï¼ˆä½¿ç”¨èªç¾©è™•ç†å™¨ï¼‰
            if self.semantic_processor:
                parties = self.semantic_processor.extract_parties_semantically(user_input)
                results["parties"] = parties
                
                # æå–ç•¶äº‹äººå§“å
                plaintiff_names = [p.name for p in parties["åŸå‘Š"] if p.confidence > 0.3]
                defendant_names = [p.name for p in parties["è¢«å‘Š"] if p.confidence > 0.3]
                
                plaintiff_str = "ã€".join(plaintiff_names) if plaintiff_names else "åŸå‘Š"
                defendant_str = "ã€".join(defendant_names) if defendant_names else "è¢«å‘Š"
                
                print(f"âœ… ç•¶äº‹äººæå–: åŸå‘Š={plaintiff_str}, è¢«å‘Š={defendant_str}")
            else:
                # å‚™ç”¨ç•¶äº‹äººæå–
                plaintiff_str = "åŸå‘Š"
                defendant_str = "è¢«å‘Š"
                print("âš ï¸ ä½¿ç”¨å‚™ç”¨ç•¶äº‹äººæå–")
            
            # 3. æ¡ˆä»¶åˆ†é¡
            accident_facts = sections.get("accident_facts", user_input)
            case_type = self.determine_case_type_semantic(accident_facts)
            results["case_type"] = case_type
            
            # 4. æå®³é …ç›®ç”Ÿæˆï¼ˆä½¿ç”¨èªç¾©è™•ç†å™¨ï¼‰
            damage_claims = sections.get("damage_claims", "")
            if self.semantic_processor and damage_claims:
                print("ğŸ’° ä½¿ç”¨èªç¾©è™•ç†å™¨åˆ†ææå®³é …ç›®...")
                
                # åˆ†ææ¡ˆä¾‹çµæ§‹
                structure = self.semantic_processor.analyze_case_structure_semantically(damage_claims, parties)
                
                # æå–å’Œåˆ†é¡é‡‘é¡
                amounts = self.semantic_processor.extract_amounts_semantically(damage_claims, structure)
                
                # ç”Ÿæˆæå®³é …ç›®
                compensation = self.semantic_processor.generate_compensation_semantically(
                    damage_claims, structure, parties, amounts
                )
                results["compensation"] = compensation
                
                # çµ±è¨ˆä¿¡æ¯
                claim_amounts = [amt for amt in amounts if amt.amount_type == "claim_amount"]
                total_amount = sum(amt.amount for amt in claim_amounts)
                results["total_amount"] = total_amount
                
                print(f"âœ… æå®³é …ç›®ç”Ÿæˆå®Œæˆï¼Œç¸½è¨ˆ: {total_amount:,}å…ƒ")
            else:
                # å‚™ç”¨æå®³é …ç›®ç”Ÿæˆ
                compensation = self._generate_fallback_compensation(damage_claims)
                results["compensation"] = compensation
                results["total_amount"] = 0
                print("âš ï¸ ä½¿ç”¨å‚™ç”¨æå®³é …ç›®ç”Ÿæˆ")
            
            # 5. ç”Ÿæˆå®Œæ•´èµ·è¨´ç‹€
            lawsuit = self._generate_complete_lawsuit(
                plaintiff_str, defendant_str, sections, compensation, case_type
            )
            results["lawsuit"] = lawsuit
            
            print("âœ… èªç¾©åŒ–èµ·è¨´ç‹€ç”Ÿæˆå®Œæˆï¼")
            return results
            
        except Exception as e:
            print(f"âŒ èªç¾©åŒ–ç”Ÿæˆå¤±æ•—: {e}")
            results["error"] = str(e)
            return results
    
    def _generate_fallback_compensation(self, damage_text: str) -> str:
        """å‚™ç”¨æå®³é …ç›®ç”Ÿæˆ"""
        # ç°¡å–®çš„é‡‘é¡æå–å’Œæ ¼å¼åŒ–
        amount_pattern = r'(\d+(?:,\d{3})*(?:\.\d{2})?)\\s*([è¬åƒ]?)å…ƒ'
        matches = re.finditer(amount_pattern, damage_text)
        
        result_lines = []
        chinese_nums = ['ä¸€', 'äºŒ', 'ä¸‰', 'å››', 'äº”', 'å…­', 'ä¸ƒ', 'å…«', 'ä¹', 'å']
        
        for i, match in enumerate(matches):
            if i < len(chinese_nums):
                amount_str = match.group(1).replace(',', '')
                unit = match.group(2)
                
                amount = float(amount_str)
                if unit == 'è¬':
                    amount *= 10000
                elif unit == 'åƒ':
                    amount *= 1000
                
                if amount >= 100:  # æ’é™¤å°é¡
                    num = chinese_nums[i]
                    result_lines.append(f"ï¼ˆ{num}ï¼‰æå®³é …ç›®ï¼š{int(amount):,}å…ƒ")
                    result_lines.append(f"åŸå‘Šå› æœ¬æ¬¡äº‹æ•…å—æœ‰æå®³ï¼Œè«‹æ±‚è³ å„Ÿ{int(amount):,}å…ƒã€‚")
                    result_lines.append("")
        
        return '\\n'.join(result_lines) if result_lines else "æœªèƒ½æå–æå®³é …ç›®"
    
    def _generate_complete_lawsuit(self, plaintiff: str, defendant: str, sections: Dict, 
                                 compensation: str, case_type: str) -> str:
        """ç”Ÿæˆå®Œæ•´èµ·è¨´ç‹€"""
        print("ğŸ“„ ç”Ÿæˆå®Œæ•´èµ·è¨´ç‹€...")
        
        prompt = f"""ä½ æ˜¯å°ç£è³‡æ·±å¾‹å¸«ï¼Œè«‹åŸºæ–¼ä»¥ä¸‹è³‡è¨Šç”Ÿæˆå®Œæ•´çš„æ°‘äº‹èµ·è¨´ç‹€ã€‚

ã€ç•¶äº‹äººè³‡è¨Šã€‘
åŸå‘Šï¼š{plaintiff}
è¢«å‘Šï¼š{defendant}
æ¡ˆä»¶é¡å‹ï¼š{case_type}

ã€æ¡ˆä»¶äº‹å¯¦ã€‘
{sections.get('accident_facts', '')}

ã€å—å‚·æƒ…å½¢ã€‘
{sections.get('injury_description', '')}

ã€æå®³è³ å„Ÿé …ç›®ã€‘
{compensation}

ã€èµ·è¨´ç‹€æ ¼å¼è¦æ±‚ã€‘
è«‹æŒ‰ç…§å°ç£æ°‘äº‹èµ·è¨´ç‹€çš„æ¨™æº–æ ¼å¼ç”Ÿæˆï¼ŒåŒ…å«ï¼š
1. æ¨™é¡Œï¼šæ°‘äº‹èµ·è¨´ç‹€
2. ç•¶äº‹äººè³‡è¨Šï¼ˆåŸå‘Šã€è¢«å‘Šï¼‰
3. æ¡ˆç”±
4. äº‹å¯¦åŠç†ç”±ï¼ˆåˆ†ç‚ºä¸€ã€äº‹å¯¦ï¼ŒäºŒã€ç†ç”±ï¼‰
5. è­‰æ“šæ–¹æ³•
6. é™„å±¬æ–‡ä»¶
7. æ³•é™¢ç®¡è½„
8. å…·ç‹€äººåŠæ—¥æœŸ

ã€é‡è¦è¦æ±‚ã€‘
- ä½¿ç”¨æ­£å¼çš„æ³•å¾‹æ–‡æ›¸èªè¨€
- äº‹å¯¦éƒ¨åˆ†è¦å®¢è§€æè¿°
- ç†ç”±éƒ¨åˆ†è¦æœ‰æ³•å¾‹ä¾æ“š
- æ ¼å¼è¦å®Œæ•´å°ˆæ¥­

è«‹ç”Ÿæˆå®Œæ•´çš„èµ·è¨´ç‹€ï¼š"""

        try:
            lawsuit = self.call_llm(prompt, timeout=300)
            print("âœ… å®Œæ•´èµ·è¨´ç‹€ç”Ÿæˆå®Œæˆ")
            return lawsuit
        except Exception as e:
            print(f"âŒ èµ·è¨´ç‹€ç”Ÿæˆå¤±æ•—: {e}")
            return f"èµ·è¨´ç‹€ç”Ÿæˆå¤±æ•—: {e}"

def interactive_generate_lawsuit():
    """äº’å‹•å¼èªç¾©åŒ–èµ·è¨´ç‹€ç”Ÿæˆ"""
    print("=" * 80)
    print("ğŸ›ï¸  è»Šç¦èµ·è¨´ç‹€ç”Ÿæˆå™¨ - èªç¾©åŒ–ç‰ˆæœ¬")
    print("=" * 80)
    print("ğŸ‘‹ æ­¡è¿ä½¿ç”¨èªç¾©åŒ–èµ·è¨´ç‹€ç”Ÿæˆå™¨ï¼ç‰¹è‰²åŠŸèƒ½ï¼š")
    print("   ğŸ§  èªç¾©ç†è§£ï¼šåŸºæ–¼LLMçš„æ·±åº¦æ–‡æœ¬ç†è§£")
    print("   ğŸ“Š æ™ºèƒ½åˆ†æï¼šè‡ªå‹•è­˜åˆ¥ç•¶äº‹äººã€é‡‘é¡åˆ†é¡")
    print("   ğŸ¯ çœŸæ­£æ³›åŒ–ï¼šé©æ‡‰å„ç¨®æ–‡æœ¬æ ¼å¼")
    print("   ğŸ“„ å®Œæ•´ç”Ÿæˆï¼šå°ˆæ¥­çš„æ³•å¾‹æ–‡æ›¸")
    print()
    
    print("ğŸ“ ä½¿ç”¨æ–¹æ³•ï¼š")
    print("   1. è«‹ä¸€æ¬¡æ€§è¼¸å…¥å®Œæ•´çš„æ¡ˆä»¶è³‡æ–™")
    print("   2. å¯ä»¥å¤šè¡Œè¼¸å…¥ï¼Œæ›è¡Œç¹¼çºŒ")
    print("   3. è¼¸å…¥å®Œæˆå¾Œè¼¸å…¥ 'END' ç¢ºèª")
    print("   4. è¼¸å…¥ 'quit' å¯é€€å‡ºç¨‹å¼")
    print()
    
    # åˆå§‹åŒ–èªç¾©ç”Ÿæˆå™¨
    generator = SemanticLawsuitGenerator()
    
    print("ğŸ“ è«‹è¼¸å…¥å®Œæ•´çš„è»Šç¦æ¡ˆä»¶è³‡æ–™ï¼š")
    print("ğŸ“‹ å»ºè­°åŒ…å«ä»¥ä¸‹å…§å®¹ï¼š")
    print("   â€¢ äº‹æ•…ç™¼ç”Ÿç¶“éå’Œè²¬ä»»æ­¸å±¬")
    print("   â€¢ åŸå‘Šå—å‚·æƒ…å½¢å’Œå°±é†«éç¨‹")
    print("   â€¢ å…·é«”çš„æå®³é …ç›®å’Œé‡‘é¡")
    print("   â€¢ ç•¶äº‹äººå§“åï¼ˆåŸå‘Šã€è¢«å‘Šï¼‰")
    print()
    print("ğŸ’¡ æç¤ºï¼šèªç¾©ç³»çµ±èƒ½ç†è§£è‡ªç„¶èªè¨€ï¼Œç„¡éœ€ç‰¹å®šæ ¼å¼")
    print("=" * 60)
    print("ğŸ¯ è«‹é–‹å§‹è¼¸å…¥ï¼ˆå®Œæˆå¾Œè¼¸å…¥ 'END' ç¢ºèªï¼‰ï¼š")
    
    # å¤šè¡Œè¼¸å…¥æ¨¡å¼
    user_input_lines = []
    while True:
        try:
            line = input()
            if line.strip().upper() in ['END', 'QUIT', 'EXIT', 'é€€å‡º']:
                if line.strip().upper() in ['QUIT', 'EXIT'] or line.strip() == 'é€€å‡º':
                    print("ğŸ‘‹ æ„Ÿè¬ä½¿ç”¨èªç¾©åŒ–èµ·è¨´ç‹€ç”Ÿæˆå™¨ï¼Œå†è¦‹ï¼")
                    return
                break
            user_input_lines.append(line)
        except KeyboardInterrupt:
            print("\\nğŸ‘‹ ç”¨æˆ¶ä¸­æ–·ï¼Œç¨‹åºé€€å‡º")
            return
        except EOFError:
            break
    
    user_query = '\\n'.join(user_input_lines).strip()
    
    if not user_query:
        print("âš ï¸ è«‹è¼¸å…¥æœ‰æ•ˆçš„å…§å®¹")
        return
    
    print("\\nğŸ”„ èªç¾©åŒ–è™•ç†ä¸­...")
    
    try:
        # ä½¿ç”¨èªç¾©ç”Ÿæˆå™¨è™•ç†
        results = generator.generate_semantic_lawsuit(user_query)
        
        if "error" not in results:
            print("\\n" + "=" * 80)
            print("ğŸ“„ ç”Ÿæˆçš„èµ·è¨´ç‹€")
            print("=" * 80)
            print(results.get("lawsuit", "æœªç”Ÿæˆ"))
            
            print("\\n" + "=" * 80)
            print("ğŸ“Š åˆ†ææ‘˜è¦")
            print("=" * 80)
            print(f"æ¡ˆä»¶é¡å‹ï¼š{results.get('case_type', 'æœªåˆ†é¡')}")
            
            if "parties" in results:
                parties = results["parties"]
                plaintiffs = [p.name for p in parties["åŸå‘Š"] if p.confidence > 0.3]
                defendants = [p.name for p in parties["è¢«å‘Š"] if p.confidence > 0.3]
                print(f"åŸå‘Šï¼š{plaintiffs}")
                print(f"è¢«å‘Šï¼š{defendants}")
            
            total_amount = results.get("total_amount", 0)
            if total_amount > 0:
                print(f"è«‹æ±‚ç¸½é¡ï¼š{total_amount:,}å…ƒ")
            
            print("\\nâœ… èªç¾©åŒ–èµ·è¨´ç‹€ç”Ÿæˆå®Œæˆï¼")
        else:
            print(f"âŒ è™•ç†å¤±æ•—ï¼š{results['error']}")
            
    except Exception as e:
        print(f"âŒ ç¨‹åºåŸ·è¡ŒéŒ¯èª¤ï¼š{str(e)}")
        import traceback
        traceback.print_exc()

def main():
    """ä¸»ç¨‹åº"""
    try:
        print("ğŸš€ å•Ÿå‹•èªç¾©åŒ–æ³•å¾‹æ–‡ä»¶è™•ç†ç³»çµ±...")
        print("=" * 80)
        print("ğŸ“Š ç³»çµ±ç‹€æ…‹æª¢æŸ¥ï¼š")
        print(f"ğŸŒ LLMæœå‹™ï¼š{'å¯ç”¨' if LLM_URL else 'ä¸å¯ç”¨'}")
        print(f"ğŸ” æª¢ç´¢åŠŸèƒ½ï¼š{'å®Œæ•´æ¨¡å¼' if FULL_MODE else 'ç°¡åŒ–æ¨¡å¼'}")
        print(f"ğŸ§  èªç¾©è™•ç†å™¨ï¼š{'å¯ç”¨' if SEMANTIC_PROCESSOR_AVAILABLE else 'ä¸å¯ç”¨'}")
        print()
        
        # å•Ÿå‹•äº’å‹•ç•Œé¢
        interactive_generate_lawsuit()
        
    except KeyboardInterrupt:
        print("\\n\\nğŸ‘‹ ç”¨æˆ¶ä¸­æ–·ï¼Œç¨‹åºé€€å‡º")
    except Exception as e:
        print(f"\\nâŒ ç¨‹åºåŸ·è¡ŒéŒ¯èª¤ï¼š{str(e)}")

if __name__ == "__main__":
    main()