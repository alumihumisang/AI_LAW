#!/usr/bin/env python3
"""
KG_700_Semantic_Universal.py
åŸºæ–¼èªç¾©ç†è§£çš„é€šç”¨æ³•å¾‹æ–‡ä»¶è™•ç†ç³»çµ±
çœŸæ­£çš„æ³›åŒ–èƒ½åŠ›ï¼Œä¸ä¾è³´ç¡¬ç·¨ç¢¼æ¨¡å¼åŒ¹é…
"""

import os
import re
import json
import requests
import time
import sys
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass

# ===== åŸºæœ¬è¨­å®š =====
LLM_URL = "http://localhost:11434/api/generate"
DEFAULT_MODEL = "gemma3:27b"

@dataclass
class PartyInfo:
    """ç•¶äº‹äººä¿¡æ¯"""
    name: str
    role: str  # åŸå‘Š/è¢«å‘Š
    confidence: float

@dataclass
class AmountInfo:
    """é‡‘é¡ä¿¡æ¯"""
    amount: int
    amount_type: str  # claim/calculation_base/unclear
    description: str
    confidence: float
    context: str

@dataclass
class CaseStructure:
    """æ¡ˆä¾‹çµæ§‹"""
    case_type: str  # single/multi_plaintiff/multi_defendant/multi_party
    plaintiff_count: int
    defendant_count: int
    narrative_style: str
    confidence: float

class SemanticLegalProcessor:
    """åŸºæ–¼èªç¾©ç†è§£çš„æ³•å¾‹æ–‡ä»¶è™•ç†å™¨"""
    
    def __init__(self, model_name: str = DEFAULT_MODEL):
        self.model_name = model_name
        self.llm_url = LLM_URL
        
        # æª¢æŸ¥LLMé€£æ¥
        self.llm_available = self._check_llm_connection()
        
    def _check_llm_connection(self) -> bool:
        """æª¢æŸ¥LLMæœå‹™æ˜¯å¦å¯ç”¨"""
        try:
            response = requests.post(
                self.llm_url,
                json={"model": self.model_name, "prompt": "test", "stream": False},
                timeout=30
            )
            if response.status_code == 200:
                result = response.json()
                return 'response' in result
            return False
        except Exception as e:
            print(f"âš ï¸ LLMæœå‹™ä¸å¯ç”¨ï¼Œå°‡ä½¿ç”¨åŸºæœ¬æ¨¡å¼: {e}")
            return False
    
    def call_llm(self, prompt: str, timeout: int = 60) -> str:
        """èª¿ç”¨LLM"""
        if not self.llm_available:
            return "LLMæœå‹™ä¸å¯ç”¨"
            
        try:
            response = requests.post(
                self.llm_url,
                json={
                    "model": self.model_name,
                    "prompt": prompt,
                    "stream": False
                },
                timeout=timeout
            )
            
            if response.status_code == 200:
                result = response.json()
                return result.get("response", "").strip()
            else:
                return f"LLMèª¿ç”¨å¤±æ•—: {response.status_code}"
                
        except Exception as e:
            return f"LLMèª¿ç”¨éŒ¯èª¤: {e}"
    
    def extract_parties_semantically(self, text: str) -> Dict[str, List[PartyInfo]]:
        """åŸºæ–¼èªç¾©ç†è§£æå–ç•¶äº‹äºº - å®Œå…¨ä¾è³´LLMèªç¾©ç†è§£"""
        print("ğŸ¤– ä½¿ç”¨èªç¾©ç†è§£æå–ç•¶äº‹äºº...")
        
        prompt = f"""ä½ æ˜¯æ³•å¾‹æ–‡ä»¶åˆ†æå°ˆå®¶ï¼Œè«‹å¾ä»¥ä¸‹æ–‡æœ¬ä¸­æå–æ‰€æœ‰ç•¶äº‹äººçš„å®Œæ•´å§“åã€‚

ã€æ–‡æœ¬å…§å®¹ã€‘
{text}

ã€æå–è¦æ±‚ã€‘
1. åªæå–ã€ŒåŸå‘Šã€ã€ã€Œè¢«å‘Šã€ã€ã€Œè¨´å¤–äººã€çš„çœŸå¯¦å§“å
2. **é‡è¦**ï¼šå¿…é ˆä¿æŒå§“åçš„å®Œæ•´æ€§ï¼Œçµ•å°ä¸å¯æˆªæ–·æˆ–çœç•¥ä»»ä½•å­—
3. **é‡è¦**ï¼šå¦‚æœåŸæ–‡æ˜¯ã€ŒåŸå‘Šç¾…é–å´´ã€ï¼Œå¿…é ˆæå–å®Œæ•´çš„ã€Œç¾…é–å´´ã€ä¸‰å€‹å­—
4. **é‡è¦**ï¼šå¦‚æœåŸæ–‡æ˜¯ã€ŒåŸå‘Šæ­é™½å¤©è¯ã€ï¼Œå¿…é ˆæå–å®Œæ•´çš„ã€Œæ­é™½å¤©è¯ã€å››å€‹å­—
5. å¿½ç•¥è·ç¨±ã€æè¿°æ€§æ–‡å­—ï¼Œåªè¦ç´”ç²¹çš„å§“å
6. å¦‚æœæ²’æœ‰å…·é«”å§“åï¼Œå°±ç”¨ã€ŒåŸå‘Šã€ã€ã€Œè¢«å‘Šã€è¡¨ç¤º

ã€è¼¸å‡ºæ ¼å¼ã€‘
è«‹è¼¸å‡ºJSONæ ¼å¼ï¼Œä¾‹å¦‚ï¼š
{{
    "åŸå‘Š": ["å¼µä¸‰", "æå››"],
    "è¢«å‘Š": ["ç‹äº”"],
    "è¨´å¤–äºº": ["è¶™å…­"]
}}

ã€é‡è¦æé†’ã€‘
- å§“åå®Œæ•´æ€§æ˜¯æœ€é‡è¦çš„ï¼Œçµ•å°ä¸èƒ½æˆªæ–·
- è¤‡å§“ï¼ˆå¦‚æ­é™½ã€å¸é¦¬ã€ä¸Šå®˜ç­‰ï¼‰å¿…é ˆå®Œæ•´ä¿ç•™
- ä¸‰å­—å§“åã€å››å­—å§“åéƒ½å¿…é ˆå®Œæ•´ä¿ç•™

è«‹åˆ†æä¸¦è¼¸å‡ºJSONï¼š"""

        try:
            response = self.call_llm(prompt, timeout=90)
            
            # è§£æJSONå›æ‡‰
            try:
                # å˜—è©¦ç›´æ¥è§£æJSON
                parties_data = json.loads(response)
            except:
                # å¦‚æœJSONè§£æå¤±æ•—ï¼Œå˜—è©¦æå–JSONéƒ¨åˆ†
                json_match = re.search(r'\{.*\}', response, re.DOTALL)
                if json_match:
                    parties_data = json.loads(json_match.group(0))
                else:
                    print(f"âŒ JSONè§£æå¤±æ•—: {response}")
                    return self._fallback_party_extraction(text)
            
            # è½‰æ›ç‚ºPartyInfoæ ¼å¼
            result = {"åŸå‘Š": [], "è¢«å‘Š": [], "è¨´å¤–äºº": []}
            
            for role, names in parties_data.items():
                if role in result and isinstance(names, list):
                    for name in names:
                        if isinstance(name, str) and len(name.strip()) > 0:
                            # èªç¾©è©•ä¼°å§“åç½®ä¿¡åº¦
                            confidence = self._assess_name_confidence_semantic(name, text)
                            result[role].append(PartyInfo(name.strip(), role, confidence))
            
            print(f"ğŸ¯ èªç¾©æå–çµæœ:")
            for role, party_list in result.items():
                if party_list:
                    names = [f"{p.name}({p.confidence:.2f})" for p in party_list]
                    print(f"   {role}: {names}")
            
            return result
            
        except Exception as e:
            print(f"âŒ èªç¾©æå–å¤±æ•—: {e}")
            return self._fallback_party_extraction(text)
    
    def _assess_name_confidence_semantic(self, name: str, context: str) -> float:
        """åŸºæ–¼èªç¾©è©•ä¼°å§“åç½®ä¿¡åº¦"""
        confidence = 0.5  # åŸºç¤ç½®ä¿¡åº¦
        
        # é•·åº¦åˆç†æ€§
        if 2 <= len(name) <= 4:
            confidence += 0.3
        elif len(name) == 1:
            confidence += 0.1
        
        # å­—ç¬¦é¡å‹ï¼ˆä¸­æ–‡å§“åï¼‰
        if re.match(r'^[\u4e00-\u9fff]+$', name):
            confidence += 0.2
        
        # åœ¨ä¸Šä¸‹æ–‡ä¸­çš„å‡ºç¾é »ç‡
        appearances = context.count(name)
        if appearances > 1:
            confidence += 0.1
        
        # å¸¸è¦‹æ³•å¾‹ç”¨è©æ’é™¤
        legal_terms = ['å› ', 'è€Œ', 'å—', 'æœ‰', 'ä¹‹', 'æ', 'å®³', 'è²»', 'ç”¨', 'å…ƒ', 'è³ ', 'å„Ÿ']
        if any(term in name for term in legal_terms):
            confidence -= 0.3
        
        return max(0.1, min(1.0, confidence))
    
    def _fallback_party_extraction(self, text: str) -> Dict[str, List[PartyInfo]]:
        """å‚™ç”¨ç•¶äº‹äººæå–æ–¹æ³•"""
        print("ğŸ”„ ä½¿ç”¨å‚™ç”¨æå–æ–¹æ³•...")
        result = {"åŸå‘Š": [], "è¢«å‘Š": [], "è¨´å¤–äºº": []}
        
        # ç°¡å–®æ¨¡å¼ï¼šè‡³å°‘èƒ½è­˜åˆ¥æœ‰ç•¶äº‹äººå­˜åœ¨
        if "åŸå‘Š" in text:
            result["åŸå‘Š"].append(PartyInfo("åŸå‘Š", "åŸå‘Š", 0.5))
        if "è¢«å‘Š" in text:
            result["è¢«å‘Š"].append(PartyInfo("è¢«å‘Š", "è¢«å‘Š", 0.5))
            
        return result
    
    def analyze_case_structure_semantically(self, text: str, parties: Dict[str, List[PartyInfo]]) -> CaseStructure:
        """åŸºæ–¼èªç¾©åˆ†ææ¡ˆä¾‹çµæ§‹"""
        print("ğŸ” åˆ†ææ¡ˆä¾‹çµæ§‹...")
        
        plaintiff_count = len([p for p in parties["åŸå‘Š"] if p.confidence > 0.3])
        defendant_count = len([p for p in parties["è¢«å‘Š"] if p.confidence > 0.3])
        
        # åˆ¤æ–·æ¡ˆä¾‹é¡å‹
        if plaintiff_count > 1 and defendant_count > 1:
            case_type = "multi_party"
        elif plaintiff_count > 1:
            case_type = "multi_plaintiff"
        elif defendant_count > 1:
            case_type = "multi_defendant"
        else:
            case_type = "single"
        
        # åˆ¤æ–·æ•˜è¿°é¢¨æ ¼ - åŸºæ–¼èªç¾©ç‰¹å¾µ
        narrative_style = self._detect_narrative_style_semantic(text)
        
        # è¨ˆç®—çµæ§‹ç½®ä¿¡åº¦
        confidence = min(1.0, (plaintiff_count + defendant_count) * 0.3)
        
        structure = CaseStructure(
            case_type=case_type,
            plaintiff_count=plaintiff_count,
            defendant_count=defendant_count,
            narrative_style=narrative_style,
            confidence=confidence
        )
        
        print(f"ğŸ“Š æ¡ˆä¾‹çµæ§‹: {case_type}, é¢¨æ ¼: {narrative_style}, åŸå‘Š: {plaintiff_count}, è¢«å‘Š: {defendant_count}")
        
        return structure
    
    def _detect_narrative_style_semantic(self, text: str) -> str:
        """åŸºæ–¼èªç¾©æª¢æ¸¬æ•˜è¿°é¢¨æ ¼"""
        # çµæ§‹åŒ–æ¨™è¨˜
        if re.search(r'[ï¼ˆ(][ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å][ï¼‰)]', text):
            return 'structured_chinese'
        elif re.search(r'\d+\.', text):
            return 'numbered_list'
        
        # åŸºæ–¼èªç¾©å¯†åº¦
        sentences = text.split('ã€‚')
        if len(sentences) > 15:
            return 'detailed_narrative'
        elif len(sentences) > 8:
            return 'standard_narrative'
        else:
            return 'simple_narrative'
    
    def extract_amounts_semantically(self, text: str, structure: CaseStructure) -> List[AmountInfo]:
        """åŸºæ–¼èªç¾©ç†è§£æå–é‡‘é¡"""
        print("ğŸ’° ä½¿ç”¨èªç¾©ç†è§£æå–é‡‘é¡...")
        
        prompt = f"""ä½ æ˜¯æ³•å¾‹æ–‡ä»¶åˆ†æå°ˆå®¶ï¼Œè«‹å¾ä»¥ä¸‹æå®³è³ å„Ÿæè¿°ä¸­æå–æ‰€æœ‰ç›¸é—œé‡‘é¡ä¸¦åˆ†é¡ã€‚

ã€æ–‡æœ¬å…§å®¹ã€‘
{text}

ã€æ¡ˆä¾‹ç‰¹å¾µã€‘
- æ¡ˆä¾‹é¡å‹: {structure.case_type}
- åŸå‘Šæ•¸é‡: {structure.plaintiff_count}

ã€åˆ†æè¦æ±‚ã€‘
1. æ‰¾å‡ºæ‰€æœ‰é‡‘é¡æ•¸å­—
2. å€åˆ†æ¯å€‹é‡‘é¡çš„æ€§è³ªï¼š
   - claim_amount: æœ€çµ‚çš„æ±‚å„Ÿé‡‘é¡ï¼ˆå¦‚"è«‹æ±‚è³ å„Ÿ10è¬å…ƒ"ã€"æ”¯å‡ºé†«ç™‚è²»5è¬å…ƒ"ï¼‰
   - calculation_base: è¨ˆç®—åŸºæº–æ•¸æ“šï¼ˆå¦‚"æœˆè–ª3è¬å…ƒ"ã€"æ¯æ—¥2000å…ƒä½œç‚ºè¨ˆç®—åŸºæº–"ï¼‰
   - unclear: æ€§è³ªä¸æ˜ç¢ºçš„é‡‘é¡

ã€ç‰¹åˆ¥æ³¨æ„ã€‘
- "XXXå…ƒè¨ˆç®—"ã€"ä½œç‚ºè¨ˆç®—åŸºæº–"ã€"æœˆè–ª"ã€"æ—¥è–ª"ç­‰é€šå¸¸æ˜¯calculation_base
- "è«‹æ±‚"ã€"è³ å„Ÿ"ã€"æ”¯å‡º"ã€"æå¤±"ç­‰é€šå¸¸æ˜¯claim_amount

ã€è¼¸å‡ºæ ¼å¼ã€‘
è«‹è¼¸å‡ºJSONæ ¼å¼ï¼Œä¾‹å¦‚ï¼š
[
    {{"amount": 50000, "type": "claim_amount", "description": "é†«ç™‚è²»ç”¨", "context": "æ”¯å‡ºé†«ç™‚è²»ç”¨5è¬å…ƒ"}},
    {{"amount": 30000, "type": "calculation_base", "description": "æœˆè–ªåŸºæº–", "context": "æœˆè–ª3è¬å…ƒè¨ˆç®—"}}
]

è«‹åˆ†æä¸¦è¼¸å‡ºJSONï¼š"""

        try:
            response = self.call_llm(prompt, timeout=120)
            
            # è§£æJSONå›æ‡‰
            try:
                amounts_data = json.loads(response)
            except:
                json_match = re.search(r'\\[.*\\]', response, re.DOTALL)
                if json_match:
                    amounts_data = json.loads(json_match.group(0))
                else:
                    print(f"âŒ é‡‘é¡JSONè§£æå¤±æ•—ï¼Œä½¿ç”¨å‚™ç”¨æ–¹æ³•")
                    return self._fallback_amount_extraction(text)
            
            # è½‰æ›ç‚ºAmountInfoæ ¼å¼
            result = []
            for item in amounts_data:
                if isinstance(item, dict) and "amount" in item:
                    amount_info = AmountInfo(
                        amount=int(item.get("amount", 0)),
                        amount_type=item.get("type", "unclear"),
                        description=item.get("description", ""),
                        confidence=0.8,  # LLMèªç¾©åˆ†æçš„é«˜ç½®ä¿¡åº¦
                        context=item.get("context", "")
                    )
                    result.append(amount_info)
            
            print(f"ğŸ’° èªç¾©æå–é‡‘é¡çµæœ:")
            for amt in result:
                print(f"   {amt.amount:,}å…ƒ - {amt.amount_type} ({amt.description})")
            
            return result
            
        except Exception as e:
            print(f"âŒ èªç¾©é‡‘é¡æå–å¤±æ•—: {e}")
            return self._fallback_amount_extraction(text)
    
    def _fallback_amount_extraction(self, text: str) -> List[AmountInfo]:
        """å‚™ç”¨é‡‘é¡æå–æ–¹æ³•"""
        print("ğŸ”„ ä½¿ç”¨å‚™ç”¨é‡‘é¡æå–...")
        result = []
        
        # åŸºæœ¬çš„é‡‘é¡æ¨¡å¼åŒ¹é…
        amount_pattern = r'(\\d+(?:,\\d{3})*(?:\\.\\d{2})?)\\s*([è¬åƒ]?)å…ƒ'
        matches = re.finditer(amount_pattern, text)
        
        for match in matches:
            amount_str = match.group(1).replace(',', '')
            unit = match.group(2)
            
            amount = float(amount_str)
            if unit == 'è¬':
                amount *= 10000
            elif unit == 'åƒ':
                amount *= 1000
            
            if amount >= 100:  # æ’é™¤å°é¡
                result.append(AmountInfo(
                    amount=int(amount),
                    amount_type="unclear",
                    description="å‚™ç”¨æå–",
                    confidence=0.3,
                    context=match.group(0)
                ))
        
        return result
    
    def generate_compensation_semantically(self, text: str, structure: CaseStructure, parties: Dict[str, List[PartyInfo]], amounts: List[AmountInfo]) -> str:
        """åŸºæ–¼èªç¾©ç†è§£ç”Ÿæˆæå®³è³ å„Ÿé …ç›®"""
        print("ğŸ“ ä½¿ç”¨èªç¾©ç†è§£ç”Ÿæˆæå®³é …ç›®...")
        
        # æå–æœ‰æ•ˆçš„æ±‚å„Ÿé‡‘é¡
        claim_amounts = [amt for amt in amounts if amt.amount_type == "claim_amount"]
        
        # æ§‹å»ºæ™ºèƒ½æç¤ºè©
        prompt = self._build_semantic_prompt(text, structure, parties, claim_amounts)
        
        try:
            result = self.call_llm(prompt, timeout=180)
            
            # å¾Œè™•ç†ï¼šæ¸…ç†å’Œé©—è­‰
            result = self._post_process_compensation(result, claim_amounts)
            
            return result
            
        except Exception as e:
            print(f"âŒ èªç¾©ç”Ÿæˆå¤±æ•—: {e}")
            return self._fallback_compensation_generation(text, parties, amounts)
    
    def _build_semantic_prompt(self, text: str, structure: CaseStructure, parties: Dict[str, List[PartyInfo]], amounts: List[AmountInfo]) -> str:
        """æ§‹å»ºåŸºæ–¼èªç¾©çš„æ™ºèƒ½æç¤ºè©"""
        
        # å‹•æ…‹æå–ç•¶äº‹äººä¿¡æ¯
        plaintiff_names = [p.name for p in parties["åŸå‘Š"] if p.confidence > 0.3]
        defendant_names = [p.name for p in parties["è¢«å‘Š"] if p.confidence > 0.3]
        
        plaintiff_str = "ã€".join(plaintiff_names) if plaintiff_names else "åŸå‘Š"
        defendant_str = "ã€".join(defendant_names) if defendant_names else "è¢«å‘Š"
        
        # æå–é‡‘é¡ä¿¡æ¯
        amount_summary = []
        for amt in amounts:
            amount_summary.append(f"{amt.amount:,}å…ƒ({amt.description})")
        
        # æ ¹æ“šæ¡ˆä¾‹é¡å‹é¸æ“‡æ ¼å¼ç­–ç•¥
        if structure.case_type == "multi_plaintiff":
            format_instruction = f"""æŒ‰åŸå‘Šåˆ†çµ„æ ¼å¼ï¼š
ï¼ˆä¸€ï¼‰åŸå‘Š[å§“å]ä¹‹æå®³ï¼š
1. æå®³é¡å‹ï¼šé‡‘é¡å…ƒ
åŸå‘Š[å§“å]å› æœ¬æ¬¡äº‹æ•…[ç°¡æ½”ç†ç”±]ï¼Œæ”¯å‡º/å—æœ‰[æå®³é¡å‹]é‡‘é¡å…ƒã€‚

ï¼ˆäºŒï¼‰åŸå‘Š[å§“å]ä¹‹æå®³ï¼š
1. æå®³é¡å‹ï¼šé‡‘é¡å…ƒ
åŸå‘Š[å§“å]å› æœ¬æ¬¡äº‹æ•…[ç°¡æ½”ç†ç”±]ï¼Œæ”¯å‡º/å—æœ‰[æå®³é¡å‹]é‡‘é¡å…ƒã€‚"""
        else:
            format_instruction = """çµ±ä¸€æ ¼å¼ï¼š
ï¼ˆä¸€ï¼‰æå®³é¡å‹ï¼šé‡‘é¡å…ƒ
åŸå‘Šå› æœ¬æ¬¡äº‹æ•…[ç°¡æ½”ç†ç”±]ï¼Œæ”¯å‡º/å—æœ‰[æå®³é¡å‹]é‡‘é¡å…ƒã€‚"""
        
        prompt = f"""ä½ æ˜¯å°ç£è³‡æ·±å¾‹å¸«ï¼Œè«‹åŸºæ–¼ä»¥ä¸‹åˆ†æçµæœç”Ÿæˆå°ˆæ¥­çš„æå®³è³ å„Ÿé …ç›®ã€‚

ã€æ¡ˆä¾‹åˆ†æçµæœã€‘
- æ¡ˆä¾‹é¡å‹ï¼š{structure.case_type}
- æ•˜è¿°é¢¨æ ¼ï¼š{structure.narrative_style}
- åŸå‘Šï¼š{plaintiff_str}ï¼ˆ{structure.plaintiff_count}åï¼‰
- è¢«å‘Šï¼š{defendant_str}
- è­˜åˆ¥é‡‘é¡ï¼š{amount_summary}

ã€åŸå§‹æå®³æè¿°ã€‘
{text}

ã€ç”Ÿæˆè¦æ±‚ã€‘
1. **é‡è¦**ï¼šåªä½¿ç”¨å·²è­˜åˆ¥çš„æœ‰æ•ˆæ±‚å„Ÿé‡‘é¡ï¼Œå¿½ç•¥è¨ˆç®—åŸºæº–
2. **é‡è¦**ï¼šä¿æŒåŸå‘Šå§“åçš„å®Œæ•´æ€§ï¼Œä¸å¯æˆªæ–·
3. **é‡è¦**ï¼šæŒ‰æ¡ˆä¾‹é¡å‹ä½¿ç”¨é©ç•¶çš„åˆ†çµ„æ ¼å¼
4. æ¯é …ç†ç”±1-2å¥è©±ï¼Œç°¡æ½”æ˜ç­
5. ä½¿ç”¨åƒåˆ†ä½é€—è™Ÿæ ¼å¼é¡¯ç¤ºé‡‘é¡
6. ä¸è¦åŒ…å«ç¸½è¨ˆã€ç¶œä¸Šæ‰€è¿°ç­‰çµè«–æ€§æ–‡å­—

ã€è¼¸å‡ºæ ¼å¼ã€‘
{format_instruction}

ã€åš´æ ¼ç¦æ­¢ã€‘
- ä¸å¯æˆªæ–·æˆ–ä¿®æ”¹åŸå‘Šå§“å
- ä¸å¯åŒ…å«è¨ˆç®—åŸºæº–é‡‘é¡
- ä¸å¯å‰µé€ ä¸å­˜åœ¨çš„æå®³é …ç›®
- ä¸å¯åŒ…å«ç¸½é‡‘é¡è¨ˆç®—

è«‹åŸºæ–¼æ¡ˆä¾‹ç‰¹å¾µç”Ÿæˆå°ˆæ¥­çš„æå®³é …ç›®ï¼š"""

        return prompt
    
    def _post_process_compensation(self, text: str, amounts: List[AmountInfo]) -> str:
        """å¾Œè™•ç†æå®³è³ å„Ÿæ–‡æœ¬"""
        # åŸºæœ¬æ¸…ç†
        lines = text.split('\\n')
        cleaned_lines = []
        
        for line in lines:
            line = line.strip()
            if line and not any(keyword in line for keyword in ['ç¸½è¨ˆ', 'ç¶œä¸Š', 'åˆè¨ˆ']):
                cleaned_lines.append(line)
        
        return '\\n'.join(cleaned_lines)
    
    def _fallback_compensation_generation(self, text: str, parties: Dict[str, List[PartyInfo]], amounts: List[AmountInfo]) -> str:
        """å‚™ç”¨æå®³é …ç›®ç”Ÿæˆ"""
        print("ğŸ”„ ä½¿ç”¨å‚™ç”¨ç”Ÿæˆæ–¹æ³•...")
        
        result_lines = []
        chinese_nums = ['ä¸€', 'äºŒ', 'ä¸‰', 'å››', 'äº”', 'å…­', 'ä¸ƒ', 'å…«', 'ä¹', 'å']
        
        claim_amounts = [amt for amt in amounts if amt.amount_type in ["claim_amount", "unclear"]]
        
        for i, amt in enumerate(claim_amounts):
            if i < len(chinese_nums):
                num = chinese_nums[i]
                result_lines.append(f"ï¼ˆ{num}ï¼‰æå®³é …ç›®ï¼š{amt.amount:,}å…ƒ")
                result_lines.append(f"åŸå‘Šå› æœ¬æ¬¡äº‹æ•…å—æœ‰æå®³ï¼Œè«‹æ±‚è³ å„Ÿ{amt.amount:,}å…ƒã€‚")
                result_lines.append("")
        
        return '\\n'.join(result_lines)
    
    def generate_cot_conclusion_semantic(self, accident_facts: str, compensation_text: str, parties: Dict[str, List[PartyInfo]], amounts: List[AmountInfo]) -> str:
        """åŸºæ–¼èªç¾©ç†è§£ç”ŸæˆCoTçµè«–"""
        print("ğŸ§  ä½¿ç”¨èªç¾©ç†è§£ç”ŸæˆCoTçµè«–...")
        
        # è¨ˆç®—ç¸½é‡‘é¡
        claim_amounts = [amt for amt in amounts if amt.amount_type == "claim_amount"]
        total_amount = sum(amt.amount for amt in claim_amounts)
        
        # æå–ç•¶äº‹äººå§“å
        plaintiff_names = [p.name for p in parties["åŸå‘Š"] if p.confidence > 0.3]
        defendant_names = [p.name for p in parties["è¢«å‘Š"] if p.confidence > 0.3]
        
        plaintiff_str = "ã€".join(plaintiff_names) if plaintiff_names else "åŸå‘Š"
        defendant_str = "ã€".join(defendant_names) if defendant_names else "è¢«å‘Š"
        
        prompt = f"""ä½ æ˜¯å°ç£è³‡æ·±å¾‹å¸«ï¼Œè«‹ä½¿ç”¨Chain of Thoughtæ¨ç†æ–¹å¼ç”Ÿæˆå°ˆæ¥­çš„èµ·è¨´ç‹€çµè«–æ®µè½ã€‚

ã€ç•¶äº‹äººè³‡è¨Šã€‘
åŸå‘Šï¼š{plaintiff_str}
è¢«å‘Šï¼š{defendant_str}

ã€æ¡ˆä»¶äº‹å¯¦ã€‘
{accident_facts}

ã€æå®³è³ å„Ÿå…§å®¹ã€‘
{compensation_text}

ã€æ™ºèƒ½é‡‘é¡åˆ†æã€‘
æœ‰æ•ˆæ±‚å„Ÿé‡‘é¡ï¼š{[amt.amount for amt in claim_amounts]}
æ­£ç¢ºç¸½è¨ˆï¼š{total_amount:,}å…ƒ

ã€CoTæ¨ç†æ­¥é©Ÿã€‘
æ­¥é©Ÿ1: åˆ†ææ¡ˆä»¶æ€§è³ªå’Œç•¶äº‹äººè²¬ä»»
æ­¥é©Ÿ2: å¾æå®³è³ å„Ÿå…§å®¹ä¸­è­˜åˆ¥å„é …æå®³é …ç›®
æ­¥é©Ÿ3: é©—è­‰å„é …é‡‘é¡çš„åˆç†æ€§
æ­¥é©Ÿ4: å½¢æˆç°¡æ½”ç²¾ç¢ºçš„çµè«–

ã€è¼¸å‡ºè¦æ±‚ã€‘
- é–‹é ­ï¼šã€Œå››ã€çµè«–ï¼šã€
- æ ¼å¼ï¼šä¸€æ®µå¼é€£çºŒæ–‡å­—ï¼Œä¸è¦æ¢åˆ—å¼
- å…§å®¹ï¼šç¶œåˆæ•˜è¿°æå®³é …ç›®å’Œç¸½é‡‘é¡
- **é‡è¦**ï¼šå¿…é ˆä½¿ç”¨æ­£ç¢ºçš„ç¸½è¨ˆé‡‘é¡{total_amount:,}å…ƒ
- **é‡è¦**ï¼šä¿æŒç•¶äº‹äººå§“åå®Œæ•´æ€§

è«‹ç”Ÿæˆå°ˆæ¥­çš„çµè«–æ®µè½ï¼š"""

        try:
            result = self.call_llm(prompt, timeout=180)
            return result if result else "å››ã€çµè«–ï¼š\\nï¼ˆèªç¾©ç”Ÿæˆå¤±æ•—ï¼Œè«‹æª¢æŸ¥è¼¸å…¥å…§å®¹ï¼‰"
        except Exception as e:
            print(f"âŒ çµè«–ç”Ÿæˆå¤±æ•—: {e}")
            return f"å››ã€çµè«–ï¼š\\nç¶œä¸Šæ‰€é™³ï¼Œè¢«å‘Šæ‡‰è³ å„ŸåŸå‘Šæå®³ç¸½è¨ˆ{total_amount:,}å…ƒã€‚"
    
    def process_case_semantically(self, text: str) -> Dict[str, Any]:
        """å®Œæ•´çš„èªç¾©åŒ–æ¡ˆä¾‹è™•ç†æµç¨‹"""
        print("ğŸš€ é–‹å§‹èªç¾©åŒ–è™•ç†æµç¨‹...")
        print("=" * 80)
        
        results = {}
        
        try:
            # 1. èªç¾©æå–ç•¶äº‹äºº
            parties = self.extract_parties_semantically(text)
            results["parties"] = parties
            
            # 2. åˆ†ææ¡ˆä¾‹çµæ§‹
            structure = self.analyze_case_structure_semantically(text, parties)
            results["structure"] = structure
            
            # 3. èªç¾©æå–é‡‘é¡
            amounts = self.extract_amounts_semantically(text, structure)
            results["amounts"] = amounts
            
            # 4. ç”Ÿæˆæå®³é …ç›®
            compensation = self.generate_compensation_semantically(text, structure, parties, amounts)
            results["compensation"] = compensation
            
            # 5. ç”Ÿæˆçµè«–
            conclusion = self.generate_cot_conclusion_semantic(text, compensation, parties, amounts)
            results["conclusion"] = conclusion
            
            # 6. çµ±è¨ˆä¿¡æ¯
            claim_amounts = [amt for amt in amounts if amt.amount_type == "claim_amount"]
            total_amount = sum(amt.amount for amt in claim_amounts)
            
            results["summary"] = {
                "total_amount": total_amount,
                "claim_count": len(claim_amounts),
                "plaintiff_count": structure.plaintiff_count,
                "defendant_count": structure.defendant_count,
                "confidence": structure.confidence
            }
            
            print("âœ… èªç¾©åŒ–è™•ç†å®Œæˆï¼")
            return results
            
        except Exception as e:
            print(f"âŒ èªç¾©åŒ–è™•ç†å¤±æ•—: {e}")
            results["error"] = str(e)
            return results

def test_semantic_system():
    """æ¸¬è©¦èªç¾©åŒ–ç³»çµ±"""
    processor = SemanticLegalProcessor()
    
    # æ¸¬è©¦æ¡ˆä¾‹ï¼šä½ æä¾›çš„å¤šåŸå‘Šæ¡ˆä¾‹
    test_case = """
æŸ¥åŸå‘Šç¾…é–å´´å› ç³»çˆ­è»Šç¦å—æœ‰å‰æ­å‚·å®³è€Œå‰å¾€è¯æ–°é†«é™¢å°±è¨ºï¼Œæœ‰è¯æ–°é†«é™¢è¨ºæ–·è­‰æ˜æ›¸å¯ä½œç‚ºè­‰æ“šï¼Œå…¶å› è€Œæ”¯å‡ºé†«ç™‚è²»ç”¨2,443å…ƒã€äº¤é€šè²»1,235å…ƒã€‚
åŸå‘Šç¾…é–å´´å› æœ¬ä»¶äº‹æ•…å—å‚·ï¼Œéœ€åœ¨å®¶ä¼‘é¤Š16æ—¥è€Œç„¡æ³•å·¥ä½œï¼ŒåˆåŸå‘Šç¾…é–å´´æ¯æœˆå·¥è³‡æ‡‰ç‚º37,778å…ƒï¼Œåˆä¾è¯æ–°é†«é™¢è¨ºæ–·è­‰æ˜æ›¸åˆ†åˆ¥æ–¼110å¹´12æœˆ4æ—¥åŠ111å¹´1æœˆ10æ—¥å»ºè­°åŸå‘Šç¾…é–å´´æ‡‰ä¼‘é¤Š3æ—¥åŠå…©é€±ï¼Œæ˜¯åŸå‘Šç¾…é–å´´æ‡‰æœ‰17æ—¥ä¸èƒ½å·¥ä½œï¼Œä½†åŸå‘Šç¾…é–å´´åƒ…è«‹æ±‚16æ—¥å·¥è³‡æå¤±ï¼Œå› æ­¤è«‹æ±‚ä¸èƒ½å·¥ä½œä¹‹æå¤±20,148å…ƒ
åŸå‘Šç¾…é–å´´å› æœ¬ä»¶è»Šç¦è€Œå—æœ‰é ­éƒ¨å¤–å‚·ä½µè¼•å¾®è…¦éœ‡ç›ªä¹‹å‚·å®³ï¼Œå½±éŸ¿æ—¥å¸¸ç”Ÿæ´»ç”šé‰…ï¼Œæ–¼ç²¾ç¥ä¸Šå¯èƒ½æ‰¿å—ä¹‹ç„¡å½¢ç—›è‹¦ï¼Œæ•…è«‹æ±‚è¢«å‘Šè³ å„Ÿ10,000å…ƒç²¾ç¥æ…°æ’«é‡‘ã€‚

åŸå‘Šé‚±å“å¦å› ç³»çˆ­è»Šç¦å—æœ‰å‰æ­å‚·å®³åŒæ¨£å‰å¾€è¯æ–°é†«é™¢é†«æ²»ï¼Œæœ‰è¯æ–°é†«é™¢è¨ºæ–·è­‰æ˜æ›¸ä½œç‚ºè­‰æ“šï¼Œå…¶å› è€Œæ”¯å‡ºé†«ç™‚è²»ç”¨57,550å…ƒã€äº¤é€šè²»22,195å…ƒã€‚
å¦å¤–åŸå‘Šé‚±å“å¦å› æœ¬ä»¶äº‹æ•…å—å‚·ï¼Œéœ€åœ¨å®¶ä¼‘é¤Š1æœˆåˆ28æ—¥è€Œç„¡æ³•å·¥ä½œï¼ŒåˆåŸå‘Šé‚±å“å¦æ¯æœˆå·¥è³‡ç‚º34,535å…ƒï¼Œåˆä¾è¯æ–°é†«é™¢è¨ºæ–·è­‰æ˜æ›¸åˆ†åˆ¥æ–¼110å¹´12æœˆ4æ—¥ã€111å¹´12æœˆ6æ—¥ã€ 110å¹´12æœˆ17æ—¥ã€110å¹´12æœˆ24æ—¥ã€111å¹´1æœˆ10æ—¥æŒçºŒå»ºè­°ä¼‘é¤Š1é€±è‡³1å€‹æœˆï¼Œç¸½è¨ˆ1å€‹æœˆåˆ28æ—¥ï¼Œå…¶ä¸èƒ½å·¥ä½œä¹‹æå¤±æ‡‰ç‚º66,768å…ƒã€‚
å¦æŸ¥ç³»çˆ­è»Šè¼›ï¼Œå› è¢«å‘Šä¹‹éå¤±è¡Œç‚ºï¼Œå—æœ‰äº¤æ˜“ä¸Šåƒ¹å€¼è²¶æ33,000å…ƒåŠæ”¯å‡ºé‘‘å®šè²»3,000å…ƒï¼Œå› æ­¤åŸå‘Šé‚±å“å¦å‘è¢«å‘Šè«‹æ±‚è³ å„Ÿä¹‹æœ¬ä»¶è»Šè¼›äº¤æ˜“åƒ¹å€¼æ¸›æåŠé‘‘å®šè²»å…±è¨ˆ36,000å…ƒã€‚
åŸå‘Šé‚±å“å¦å› æœ¬ä»¶è»Šç¦å—æœ‰é ­æšˆåŠé ¸éƒ¨æ‰­å‚·ç­‰å‚·å®³ï¼Œå½±éŸ¿å…¶å·¥ä½œã€ç”Ÿæ´»ä¹‹è¡Œå‹•ï¼Œæ–¼ç²¾ç¥ä¸Šé€ æˆç„¡å½¢ç—›è‹¦ï¼Œæ•…è«‹æ±‚è¢«å‘Šé€£å¸¶è³ å„Ÿ60,000å…ƒç²¾ç¥æ…°æ’«é‡‘ã€‚
    """
    
    print("ğŸ§ª æ¸¬è©¦èªç¾©åŒ–æ³•å¾‹æ–‡ä»¶è™•ç†ç³»çµ±")
    print("=" * 80)
    
    # åŸ·è¡Œå®Œæ•´è™•ç†
    results = processor.process_case_semantically(test_case)
    
    # é¡¯ç¤ºçµæœ
    if "error" not in results:
        print("\\nğŸ“Š è™•ç†çµæœæ‘˜è¦:")
        summary = results.get("summary", {})
        print(f"   ç¸½é‡‘é¡: {summary.get('total_amount', 0):,}å…ƒ")
        print(f"   æ±‚å„Ÿé …ç›®æ•¸: {summary.get('claim_count', 0)}")
        print(f"   åŸå‘Šæ•¸é‡: {summary.get('plaintiff_count', 0)}")
        print(f"   è¢«å‘Šæ•¸é‡: {summary.get('defendant_count', 0)}")
        
        print("\\nğŸ“ ç”Ÿæˆçš„æå®³é …ç›®:")
        print(results.get("compensation", "æœªç”Ÿæˆ"))
        
        print("\\nğŸ§  ç”Ÿæˆçš„çµè«–:")
        print(results.get("conclusion", "æœªç”Ÿæˆ"))
    else:
        print(f"âŒ è™•ç†å¤±æ•—: {results['error']}")

if __name__ == "__main__":
    print("ğŸš€ å•Ÿå‹•èªç¾©åŒ–æ³•å¾‹æ–‡ä»¶è™•ç†ç³»çµ±...")
    test_semantic_system()